{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드 실행 전 기존 json 파일이 포함된 labels 폴더 이름을 labels_json 으로 변경 후 코드실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  requirment.txt 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "requirements_file = 'requirements.txt'\n",
    "\n",
    "result = subprocess.run(['pip', 'install', '-r', requirements_file], capture_output=True, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print(\"에러 :\")\n",
    "    print(result.stderr)\n",
    "    \n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 라이브러리 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from albumentations import (Compose, RandomBrightnessContrast, Rotate, HorizontalFlip, VerticalFlip, Blur, RandomScale)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output  \n",
    "import time\n",
    "\n",
    "clear_output()\n",
    "ultralytics.checks()\n",
    "\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. YOLO 형식의 어노테이션으로 변환\n",
    "\n",
    "\n",
    "##기존 json 파일이 포함된 labels 폴더 이름을 labels_json 으로 변경 후 코드실행##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기존 json 파일이 포함된 labels 폴더 이름을 labels_json 으로 변경 후 코드실행\n",
    "\n",
    "class_map = {\n",
    "    \"road\": 0, \"sidewalk\": 1, \"road roughness\": 2, \"road boundaries\": 3, \"crosswalks\": 4, \n",
    "    \"lane\": 5, \"road color guide\": 6, \"road marking\": 7, \"parking\": 8, \"traffic sign\": 9, \n",
    "    \"traffic light\": 10, \"pole/structural object\": 11, \"building\": 12, \"tunnel\": 13, \n",
    "    \"bridge\": 14, \"pedestrian\": 15, \"vehicle\": 16, \"bicycle\": 17, \"motorcycle\": 18, \n",
    "    \"personal mobility\": 19, \"dynamic\": 20, \"vegetation\": 21, \"sky\": 22, \"static\": 23\n",
    "}\n",
    "\n",
    "def normalize_polygon(polygon, image_width, image_height):\n",
    "    normalized_polygon = []\n",
    "    for point in polygon:\n",
    "        normalized_x = point[0] / image_width\n",
    "        normalized_y = point[1] / image_height\n",
    "        normalized_polygon.extend([normalized_x, normalized_y])\n",
    "    return normalized_polygon\n",
    "\n",
    "def convert_annotation(json_file, output_file, image_size, image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file not found: {image_path}. Skipping...\")\n",
    "        return\n",
    "    \n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    annotations = data.get('Annotation', [])\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img_height, img_width = img.shape[:2]\n",
    "\n",
    "    for anno in annotations:\n",
    "        if 'data' in anno and len(anno['data']) > 0:\n",
    "            data = anno['data'][0]\n",
    "            if len(data) % 2 != 0:\n",
    "                continue\n",
    "            class_id = class_map.get(anno['class_name'], -1)\n",
    "            if class_id == -1:\n",
    "                continue\n",
    "            \n",
    "            polygon = list(zip(data[0::2], data[1::2]))\n",
    "            normalized_polygon = normalize_polygon(polygon, img_width, img_height)\n",
    "            \n",
    "            x_coords = data[0::2]\n",
    "            y_coords = data[1::2]\n",
    "            x_min, x_max = min(x_coords), max(x_coords)\n",
    "            y_min, y_max = min(y_coords), max(y_coords)\n",
    "            \n",
    "            if x_max <= x_min or y_max <= y_min:\n",
    "                print(f\"Skipping {json_file}: x_min={x_min}, x_max={x_max}, y_min={y_min}, y_max={y_max}\")\n",
    "                continue\n",
    "            \n",
    "            coordinates_str = \" \".join([f\"{coord:.6f}\" for coord in normalized_polygon])\n",
    "            with open(output_file, 'a') as f_out:\n",
    "                f_out.write(f\"{class_id} {coordinates_str}\\n\")\n",
    "\n",
    "\n",
    "def process_directory(json_dir, output_dir, image_dir, image_size=(1920, 1200)):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for json_file in os.listdir(json_dir):\n",
    "        if json_file.endswith('.json'):\n",
    "            base_name = os.path.splitext(json_file)[0]\n",
    "            output_file = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "            image_path = os.path.join(image_dir, f\"{base_name}.jpg\")\n",
    "            convert_annotation(os.path.join(json_dir, json_file), output_file, image_size, image_path)\n",
    "\n",
    "image_size = (1920, 1200)\n",
    "\n",
    "## 기존 json 파일이 포함된 labels 폴더 이름을 labels_json 으로 변경 후 코드실행\n",
    "val_json_dir = 'data/validation/labels_json'\n",
    "val_image_dir = 'data/validation/images'\n",
    "val_output_dir = 'data/validation/labels'\n",
    "process_directory(val_json_dir, val_output_dir, val_image_dir, image_size=image_size)\n",
    "\n",
    "train_json_dir = 'data/training/labels_json'\n",
    "train_image_dir = 'data/training/images'\n",
    "train_output_dir = 'data/training/labels'\n",
    "process_directory(train_json_dir, train_output_dir, train_image_dir, image_size=image_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. test mask 파일 생성\n",
    "\n",
    "##기존 json 파일이 포함된 labels 폴더 이름을 labels_json 으로 변경 후 코드실행##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image_size, annotations, class_labels):\n",
    "    width, height = image_size\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        class_name = annotation['class_name']\n",
    "        polygon = annotation['data'][0]  \n",
    "        \n",
    "        if class_name not in class_labels:\n",
    "            continue  \n",
    "\n",
    "        class_id = class_labels[class_name]\n",
    "        \n",
    "        polygon = np.array(polygon).reshape((-1, 2))\n",
    "        \n",
    "        cv2.fillPoly(mask, [polygon.astype(np.int32)], class_id)\n",
    "\n",
    "    return Image.fromarray(mask)\n",
    "\n",
    "def process_annotations(image_dir, label_dir, mask_dir):\n",
    "    if not os.path.exists(mask_dir):\n",
    "        os.makedirs(mask_dir)\n",
    "    \n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if label_file.endswith('.json'):\n",
    "            with open(os.path.join(label_dir, label_file)) as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            image_name = data[\"image_name\"]\n",
    "            image_size = tuple(data[\"image_size\"])\n",
    "            annotations = data[\"Annotation\"]\n",
    "            \n",
    "            mask = create_mask(image_size, annotations, class_map)\n",
    "            mask.save(os.path.join(mask_dir, image_name.replace('.jpg', '_mask.png')))\n",
    "\n",
    "image_dir = 'data/test/images'\n",
    "label_dir = 'data/test/labels_json'\n",
    "mask_dir = 'data/test/masks'\n",
    "\n",
    "process_annotations(image_dir, label_dir, mask_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 하이퍼파라미터 설정 및 모델 학습\n",
    "\n",
    "##새로 학습을 진행하면 runs\\segment\\train2\\weights\\best.pt 로 경로 변경해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lr0': 0.01,\n",
    "    'lrf': 0.01,\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'box': 0.05,\n",
    "    'cls': 0.5,\n",
    "    'dfl': 1.5,\n",
    "    'pose': 12.0,\n",
    "    'kobj': 1.0,\n",
    "    'label_smoothing': 0.0,\n",
    "    'nbs': 64,\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 0.0,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'flipud': 0.0,\n",
    "    'fliplr': 0.5,\n",
    "    'bgr': 0.0,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.0,\n",
    "    'copy_paste': 0.0,\n",
    "    'auto_augment': 'randaugment',\n",
    "    'erasing': 0.4,\n",
    "    'crop_fraction': 1.0\n",
    "}\n",
    "\n",
    "yaml_path = 'data.yaml'\n",
    "model = YOLO('yolov8l-seg.pt')\n",
    "model.train(data=yaml_path, epochs=50, batch=8, imgsz=640, device=0, augment=True, optimizer='SGD', **hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 예측된 마스크 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델로 예측된 마스크 파일 생성\n",
    "class_map = {\n",
    "    0: 0,  # road\n",
    "    1: 1,  # sidewalk\n",
    "    2: 2,  # road roughness\n",
    "    3: 3,  # road boundaries\n",
    "    4: 4,  # crosswalks\n",
    "    5: 5,  # lane\n",
    "    6: 6,  # road color guide\n",
    "    7: 7,  # road marking\n",
    "    8: 8,  # parking\n",
    "    9: 9,  # traffic sign\n",
    "    10: 10,  # traffic light\n",
    "    11: 11,  # pole/structural object\n",
    "    12: 12,  # building\n",
    "    13: 13,  # tunnel\n",
    "    14: 14,  # bridge\n",
    "    15: 15,  # pedestrian\n",
    "    16: 16,  # vehicle\n",
    "    17: 17,  # bicycle\n",
    "    18: 18,  # motorcycle\n",
    "    19: 19,  # personal mobility\n",
    "    20: 20,  # dynamic\n",
    "    21: 21,  # vegetation\n",
    "    22: 22,  # sky\n",
    "    23: 23   # static\n",
    "}\n",
    "\n",
    "#현재 만들어진 모델 경로\n",
    "model = YOLO(r\"runs/segment/train/weights/best.pt\")\n",
    "\n",
    "output_dir = r\"predicted_masks\"\n",
    "os.makedirs(output_dir, exist_ok=True) \n",
    "\n",
    "image_dir = r\"data/test/images\"\n",
    "image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith('.jpg')]\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width = img.shape[:2]\n",
    "    results = model.predict(img, save=False)\n",
    "\n",
    "   \n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    if results and results[0].masks:\n",
    "        for i, mask in enumerate(results[0].masks.data):\n",
    "            mask_np = mask.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            resized_mask = cv2.resize(mask_np, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            class_id = int(results[0].boxes.cls[i].item())  \n",
    "            shade_value = class_map[class_id]  \n",
    "\n",
    "            combined_mask[resized_mask > 0.5] = shade_value\n",
    "\n",
    "        unique_values = np.unique(combined_mask)\n",
    "        print(f\"Unique values in combined mask: {unique_values}\")\n",
    "\n",
    "        mask_name = os.path.splitext(os.path.basename(img_path))[0] + '_combined_mask.png'\n",
    "        mask_path = os.path.join(output_dir, mask_name)\n",
    "        cv2.imwrite(mask_path, combined_mask) \n",
    "        print(f\"Saved combined mask: {mask_path}\")\n",
    "    else:\n",
    "        print(f\"No masks found for image: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. mIoU 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#로그가 너무 길다면 mIoU 최종 print 함수 제외하고 삭제 가능\n",
    "\n",
    "def calculate_iou(pred_mask, true_mask):\n",
    "    intersection = np.logical_and(pred_mask, true_mask)\n",
    "    union = np.logical_or(pred_mask, true_mask)\n",
    "\n",
    "    print(f\"Intersection sum: {np.sum(intersection)}\")\n",
    "    print(f\"Union sum: {np.sum(union)}\")\n",
    "\n",
    "    if np.sum(union) == 0:\n",
    "        return 1.0 \n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou\n",
    "\n",
    "def load_mask(mask_path):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return mask  \n",
    "\n",
    "def visualize_masks(pred_mask, true_mask):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(pred_mask, cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(true_mask, cmap='gray')\n",
    "    plt.title('True Mask')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def calculate_miou(pred_mask_dir, true_mask_dir, mask_size=(1920, 1200)):\n",
    "    pred_mask_paths = [os.path.join(pred_mask_dir, f) for f in os.listdir(pred_mask_dir) if f.endswith('.png')]\n",
    "    true_mask_paths = [os.path.join(true_mask_dir, f) for f in os.listdir(true_mask_dir) if f.endswith('.png')]\n",
    "\n",
    "    ious = []\n",
    "    for pred_mask_path, true_mask_path in tqdm(zip(pred_mask_paths, true_mask_paths), total=len(pred_mask_paths), desc=\"Calculating mIoU\"):\n",
    "        pred_mask = load_mask(pred_mask_path)\n",
    "        true_mask = load_mask(true_mask_path)\n",
    "\n",
    "        if pred_mask.shape != true_mask.shape:\n",
    "            pred_mask = cv2.resize(pred_mask, mask_size, interpolation=cv2.INTER_NEAREST)\n",
    "            true_mask = cv2.resize(true_mask, mask_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        print(f\"Comparing: {pred_mask_path} with {true_mask_path}\")\n",
    "        print(f\"Pred mask shape: {pred_mask.shape}, True mask shape: {true_mask.shape}\")\n",
    "        print(f\"Pred mask unique values: {np.unique(pred_mask)}\")\n",
    "        print(f\"True mask unique values: {np.unique(true_mask)}\")\n",
    "\n",
    "        visualize_masks(pred_mask, true_mask)\n",
    "\n",
    "        pred_mask_binary = pred_mask > 0\n",
    "        true_mask_binary = true_mask > 0\n",
    "\n",
    "        print(f\"Binary pred mask unique values: {np.unique(pred_mask_binary)}\")\n",
    "        print(f\"Binary true mask unique values: {np.unique(true_mask_binary)}\")\n",
    "\n",
    "        iou = calculate_iou(pred_mask_binary, true_mask_binary)\n",
    "        print(f\"Calculated IoU: {iou}\")  \n",
    "        ious.append(iou)\n",
    "\n",
    "    miou = np.mean(ious)\n",
    "    return miou\n",
    "\n",
    "pred_mask_dir = r\"predicted_masks\"\n",
    "true_mask_dir = r\"data/test/masks\"\n",
    "\n",
    "miou = calculate_miou(pred_mask_dir, true_mask_dir)\n",
    "print(f\"mIoU: {miou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 성능 지표 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#현재 만들어진 모델 경로\n",
    "model = YOLO('runs/segment/train/weights/best.pt')\n",
    "\n",
    "val_data = 'data.yaml'  \n",
    "\n",
    "results = model.val(data=val_data, imgsz=640, device=0)\n",
    "\n",
    "print(f\"Box mAP@0.5: {results.box.map50:.4f}\")         \n",
    "print(f\"Box mAP@0.5:0.95: {results.box.map:.4f}\")       \n",
    "print(f\"Box Precision: {results.box.p.mean():.4f}\")     \n",
    "print(f\"Box Recall: {results.box.r.mean():.4f}\")         \n",
    "\n",
    "print(f\"Segmentation mAP@0.5: {results.seg.map50:.4f}\") \n",
    "print(f\"Segmentation mAP@0.5:0.95: {results.seg.map:.4f}\")  \n",
    "print(f\"Segmentation Precision: {results.seg.p.mean():.4f}\") \n",
    "print(f\"Segmentation Recall: {results.seg.r.mean():.4f}\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 세그멘테이션 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#현재 만들어진 모델 경로\n",
    "model_path = r\"runs\\segment\\train\\weights\\best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "test_image_path = r\"data\\test\\images\\N_SFL_230703_015_FC_246.jpg\"\n",
    "\n",
    "image = cv2.imread(test_image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "height, width, _ = image.shape\n",
    "\n",
    "class_colors = {\n",
    "    0: [255, 0, 0],   # road\n",
    "    1: [0, 255, 0],   # sidewalk\n",
    "    2: [0, 0, 255],   # road roughness\n",
    "    3: [255, 255, 0], # road boundaries\n",
    "    4: [255, 0, 255], # crosswalks\n",
    "    5: [0, 255, 255], # lane\n",
    "    6: [128, 0, 0],   # road color guide\n",
    "    7: [128, 128, 0], # road marking\n",
    "    8: [0, 128, 0],   # parking\n",
    "    9: [128, 0, 128], # traffic sign\n",
    "    10: [0, 128, 128],# traffic light\n",
    "    11: [0, 0, 128],  # pole/structural object\n",
    "    12: [128, 128, 128], # building\n",
    "    13: [64, 0, 0],   # tunnel\n",
    "    14: [64, 64, 0],  # bridge\n",
    "    15: [0, 64, 0],   # pedestrian\n",
    "    16: [64, 0, 64],  # vehicle\n",
    "    17: [0, 64, 64],  # bicycle\n",
    "    18: [192, 0, 0],  # motorcycle\n",
    "    19: [192, 192, 0],# personal mobility\n",
    "    20: [0, 192, 0],  # dynamic\n",
    "    21: [192, 0, 192],# vegetation\n",
    "    22: [0, 192, 192],# sky\n",
    "    23: [0, 0, 192]   # static\n",
    "}\n",
    "\n",
    "results = model.predict(source=image_rgb)\n",
    "\n",
    "masks = results[0].masks.data\n",
    "boxes = results[0].boxes.data\n",
    "classes = results[0].boxes.cls\n",
    "\n",
    "overlay_image = image_rgb.copy()\n",
    "for i in range(len(masks)):\n",
    "    mask = masks[i].cpu().numpy()\n",
    "    class_id = int(classes[i])\n",
    "    color = class_colors[class_id]\n",
    "\n",
    "    resized_mask = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    overlay_image[resized_mask > 0.5] = color\n",
    "\n",
    "output_dir = r\"visual\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_image_path = os.path.join(output_dir, \"output_overlay.png\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(overlay_image)\n",
    "plt.axis('off')\n",
    "plt.savefig(output_image_path, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 평균 추론 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = r\"runs\\segment\\train\\weights\\best.pt\"\n",
    "test_images_folder = r\"data\\test\\images\"\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "image_files = [f for f in os.listdir(test_images_folder) if f.endswith(('.jpg'))]\n",
    "\n",
    "times = []\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"Processing images\", disable=True):\n",
    "    image_path = os.path.join(test_images_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = model.predict(source=image_rgb, verbose=False)  \n",
    "    end_time = time.time()\n",
    "    \n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = np.mean(times)\n",
    "print(f\"Average inference time over {len(image_files)} images: {average_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
